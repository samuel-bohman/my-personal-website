---
title: Exploring Survival on the Titanic
author: Samuel Bohman
date: '2017-10-11'
slug: exploring-survival-on-the-titanic
categories: []
tags:
  - r
---

## Introduction

The sinking of the RMS Titanic in 1912 is one of the most infamous shipwrecks in history. During her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. In this project, we predict which passengers were likely to survive the tragedy. 

```{r}
# Import the train and test datasets
train_new <- read.csv("train_new.csv") 
test_new <- read.csv("test_new.csv")
all_data <- read.csv("all_data.csv")
```

## What is a Random Forest

- The code to clean your entire dataset from missing data and split it up in training and test set is provided in the sample code. Study the code chunks closely so you understand what's going on. Just click Submit Answer to continue.
- If you want to know how `all_data` itself was built from `train` and `test`, have a look at this R script.

```{r}
# All data, both training and test set
all_data

# Passenger on row 62 and 830 do not have a value for embarkment.
# Since many passengers embarked at Southampton, we give them the value S.
all_data$Embarked[c(62, 830)] <- "S"

# Factorize embarkment codes.
all_data$Embarked <- factor(all_data$Embarked)

# Passenger on row 1044 has an NA Fare value. Let's replace it with the median fare value.
all_data$Fare[1044] <- median(all_data$Fare, na.rm = TRUE)

# How to fill in missing Age values?
# We make a prediction of a passengers Age using the other variables and a decision tree model.
# This time you give method = "anova" since you are predicting a continuous variable.
library(rpart)
predicted_age <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Title + family_size, data = all_data[!is.na(all_data$Age),], method = "anova")
all_data$Age[is.na(all_data$Age)] <- predict(predicted_age, all_data[is.na(all_data$Age),])

# Split the data back into a train set and a test set
train <- all_data[1:891, ]
test <- all_data[892:1309, ]
```

## A Random Forest analysis in R

- Perform a Random Forest and name the model `my_forest`. Use the variables `Passenger Class`, `Sex`, `Age`, `Number of Siblings/Spouses Aboard`, `Number of Parents/Children Aboard`, `Passenger Fare`, `Port of Embarkation`, and `Title` (in this order).
- Set the number of trees to grow to 1000 and make sure you can inspect variable importance.
- Make a prediction (`my_prediction`) on the test set using the `predict()` function.
- Create a data frame `my_solution` that contains the solution in line with the Kaggle standards.
- Turn your solution into a csv file with the name `my_solution.csv`.

```{r}
# train and test are available in the workspace
# str(train)
# str(test)

# Load in the package
library(randomForest)

# Train set and test set
# str(train)
# str(test)

# Set seed for reproducibility
set.seed(111)

# Apply the Random Forest Algorithm
my_forest <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Title, data = train, importance = T, ntree = 1000)

# Make your prediction using the test set
my_prediction <- predict(my_forest, test)

# Create a data frame with two columns: PassengerId & Survived. Survived contains your predictions
my_solution <- data.frame(PassengerId = test$PassengerId, Survived = my_prediction)

# Write your solution away to a csv file with the name my_solution.csv
write.csv(my_solution, "my_solution.csv", row.names = F)
```

## Important variables

Your Random Forest object `my_forest` is still loaded in. Remember you set `importance = TRUE`? Now you can see what variables are important using `varImpPlot(my_forest)`. 

```{r}
varImpPlot(my_forest)
```

When running the function, two graphs appear: the accuracy plot shows how much worse the model would perform without the included variables. So a high decrease (= high value x-axis) links to a high predictive variable. The second plot is the Gini coefficient. The higher the variable scores here, the more important it is for the model.

Based on the two plots, what variable has the highest impact on the model?

- Fare
- Sex
- Title
- Age

Answer: Title. 



